# åŒ…æ‹¬çš„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°åˆ†æãƒ¬ãƒãƒ¼ãƒˆ

**æ—¥ä»˜**: 2026-01-20  
**ç›®çš„**: ã“ã‚Œã¾ã§ã®å…¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œã®çŠ¶æ³æ•´ç†ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—æ±ºå®š

---

## ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼

### ä¸»è¦ãªç™ºè¦‹ ğŸ¯

1. **æ—§ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®Iter 40ãŒç›®æ¨™é”æˆ**: Valueç›¸é–¢ **0.63** (ç›®æ¨™ >0.3)
2. **éå­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç¢ºèª**: Iter 50ã§æ€§èƒ½å´©å£Šï¼ˆ0.63 â†’ 0.13ï¼‰
3. **æ–°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯æœªå®Œäº†**: Iter 10ã§åœæ­¢ï¼ˆç›¸é–¢ 0.10ï¼‰
4. **Greedyæˆ¦ç•¥**: å…¨å®Ÿè¡Œã§0%å‹ç‡ï¼ˆåŸºæœ¬æˆ¦ç•¥æœªå­¦ç¿’ï¼‰

### æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³

âœ… **Iter 40ãƒ¢ãƒ‡ãƒ«ã®å®Ÿæˆ¦è©•ä¾¡ã‚’å®Ÿæ–½** (æ—§ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£)  
âš ï¸ Greedyæˆ¦ç•¥ã«å‹ã¦ã‚‹ã‹ç¢ºèª  
âš ï¸ æˆåŠŸãªã‚‰: Iter 40ã‚’ä½¿ç”¨ã€ã¾ãŸã¯Iter 35-45ã§æ—©æœŸåœæ­¢æˆ¦ç•¥  
âš ï¸ å¤±æ•—ãªã‚‰: ä»£æ›¿ã‚¢ãƒ—ãƒ­ãƒ¼ãƒæ¤œè¨

---

## ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæ•´ç†

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®é•ã„

| ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ | Normalization | Value Head | Params | ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çŠ¶æ³ |
|---------------|---------------|------------|--------|----------------|
| **æ—§** | BatchNorm | 32ch, shallow | 319K | Iter 15-50å®Œäº† |
| **æ–°** | GroupNorm | 64ch, deep + Dropout | 375K | Iter 5-10ã®ã¿ |

### ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¸€è¦§

| Checkpoint | æ—¥ä»˜ | ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ | Valueç›¸é–¢ | å‚™è€ƒ |
|------------|------|---------------|-----------|------|
| Iter 5 (æ–°) | Jan 19 00:30 | GroupNorm + 64ch | **-0.35** âŒ | è² ã®ç›¸é–¢ |
| Iter 10 (æ–°) | Jan 19 00:50 | GroupNorm + 64ch | **0.10** âš ï¸ | æ”¹å–„å‚¾å‘ã ãŒä½ã„ |
| Iter 15 (æ—§) | Jan 18 21:34 | BatchNorm + 32ch | **0.09** âŒ | å­¦ç¿’åˆæœŸ |
| Iter 20 (æ—§) | Jan 18 21:59 | BatchNorm + 32ch | **0.06** âŒ | ã¾ã ä½ã„ |
| Iter 30 (æ—§) | Jan 18 06:59 | BatchNorm + 32ch | **0.52** âœ… | çªç ´ |
| **Iter 40 (æ—§)** | Jan 18 07:58 | BatchNorm + 32ch | **0.63** âœ…âœ… | **æœ€é«˜æ€§èƒ½** |
| Iter 50 (æ—§) | Jan 18 08:57 | BatchNorm + 32ch | **0.13** âŒ | éå­¦ç¿’å´©å£Š |

---

## è©³ç´°åˆ†æ

### 1. æ—§ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ (BatchNorm + 32ch) - å®Œäº†

#### Value Headæ€§èƒ½æ¨ç§»

```
Iter 15:  0.09  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” (ä½è¿·æœŸ)
Iter 20:  0.06  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Iter 30:  0.52  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” (çªç ´)
Iter 40:  0.63  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” (ãƒ”ãƒ¼ã‚¯) âœ…
Iter 50:  0.13  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” (å´©å£Š)
         0.0   0.1   0.2   0.3   0.4   0.5   0.6   0.7
                            â†‘ ç›®æ¨™
```

#### Iter 40ã®è©³ç´° (æœ€é«˜æ€§èƒ½ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ)

- **Valueç›¸é–¢**: 0.63 (ç›®æ¨™ã®2å€)
- **MSE**: 0.61
- **å‹ã¡ã‚²ãƒ¼ãƒ äºˆæ¸¬**: +0.35
- **è² ã‘ã‚²ãƒ¼ãƒ äºˆæ¸¬**: -0.43
- **è‡ªå·±å¯¾æˆ¦**: 5/5ã‚²ãƒ¼ãƒ ã§P0å‹åˆ©

**ç‰¹å¾´**: å‹ã¡/è² ã‘ã‚’æ˜ç¢ºã«åŒºåˆ¥ã§ãã‚‹å€¤æ¨å®šï¼ˆ+0.35 vs -0.43ï¼‰

#### éå­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³

Iter 40 â†’ 50ã§å´©å£Šã—ãŸç†ç”±ï¼ˆä»®èª¬ï¼‰:
1. Replay bufferãªã— â†’ æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§è¨“ç·´
2. Value loss weight = 1.0 â†’ éåº¦ãªé‡ã¿
3. æ—©æœŸåœæ­¢ãªã— â†’ ãƒ”ãƒ¼ã‚¯ã‚’è¶…ãˆã¦è¨“ç·´ç¶™ç¶š

### 2. æ–°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ (GroupNorm + 64ch) - æœªå®Œäº†

#### Value Headæ€§èƒ½æ¨ç§»

```
Iter 5:  -0.35  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” (è² ã®ç›¸é–¢)
Iter 10:  0.10  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” (æ”¹å–„)
Iter ?:   ???   ?
         -0.4  -0.2   0.0   0.2   0.4   0.6
                            â†‘ ç›®æ¨™
```

**è¦³å¯Ÿ**:
- Iter 5: å€¤ã®åŒºåˆ¥ãŒã§ããªã„ï¼ˆå‹ã¡/è² ã‘ä¸¡æ–¹ã§+0.20ï¼‰
- Iter 10: æ”¹å–„ã®å…†ã—ï¼ˆ-0.35 â†’ 0.10ã€+0.46ã®å‘ä¸Šï¼‰
- **ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒIter 10ã§åœæ­¢**

**å¯èƒ½æ€§**: ç¶šã‘ã¦ã„ã‚Œã°Iter 30-40ã§çªç ´ã§ããŸå¯èƒ½æ€§ã‚ã‚Š

---

## æ—¢çŸ¥ã®å•é¡Œ

### å…¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å…±é€šã®å•é¡Œ

#### 1. Greedyæˆ¦ç•¥ã«0%å‹ç‡ âŒ

å…¨ã¦ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§å ±å‘Š:
- Iter 5 (æ–°): vs Greedy 0%
- Iter 10 (æ–°): vs Greedy 0%
- Iter 15 (æ—§): vs Greedy 0%
- Iter 20 (æ—§): vs Greedy 0%

**Greedyæˆ¦ç•¥**: å˜ç´”ã«ã€Œæœ€å¤§ã‚µã‚¤ã‚ºã®ãƒ”ãƒ¼ã‚¹ã‹ã‚‰ç½®ãã€

**å«æ„**: Value headã®ç›¸é–¢ãŒæ”¹å–„ã—ã¦ã‚‚ã€å®Ÿæˆ¦ã§ã¯åŸºæœ¬æˆ¦ç•¥ã‚’å­¦ç¿’ã§ãã¦ã„ãªã„å¯èƒ½æ€§

#### 2. è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã®æ··ä¹±

`TEST_V2_PRELIMINARY_SUMMARY.md`ã®çµæœã¯**ç•°ãªã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ··åˆ**:
- Iter 5, 10: æ–°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
- Iter 15, 20: æ—§ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

â†’ æ¯”è¼ƒãŒç„¡åŠ¹

---

## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

### Phase 1: Iter 40ã®å®Ÿæˆ¦è©•ä¾¡ âš¡ å„ªå…ˆåº¦: æœ€é«˜

**ç›®çš„**: Valueç›¸é–¢0.63ã®ãƒ¢ãƒ‡ãƒ«ãŒå®Ÿæˆ¦ã§ä½¿ãˆã‚‹ã‹ç¢ºèª

```bash
# æ—§ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ä¸€æ™‚çš„ã«æˆ»ã™
cp blokus_ai/net.py /tmp/net_new.py.backup
git show HEAD:blokus_ai/net.py > blokus_ai/net.py

# è©•ä¾¡å®Ÿè¡Œ
uv run python -c "
from blokus_ai.eval import evaluate_model
import torch
from blokus_ai.net import PolicyValueNet

net = PolicyValueNet()
net.load_state_dict(torch.load('models/checkpoints/checkpoint_iter_0040.pth'))
net.eval()

# Greedyã«å¯¾ã—ã¦20ã‚²ãƒ¼ãƒ è©•ä¾¡
print('Evaluating Iter 40 vs Greedy (20 games)...')
win_rate = evaluate_model(net, num_simulations=200, num_games=20, opponent='greedy')
print(f'Win rate: {win_rate:.1%}')

# Randomã«å¯¾ã—ã¦20ã‚²ãƒ¼ãƒ è©•ä¾¡
print('Evaluating Iter 40 vs Random (20 games)...')
win_rate = evaluate_model(net, num_simulations=200, num_games=20, opponent='random')
print(f'Win rate: {win_rate:.1%}')
"

# æ–°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«æˆ»ã™
cp /tmp/net_new.py.backup blokus_ai/net.py
```

**æˆåŠŸåŸºæº–**:
- âœ… vs Greedy > 50% â†’ **æˆåŠŸï¼Iter 40ã‚’ä½¿ç”¨**
- âš ï¸ vs Greedy 10-50% â†’ éƒ¨åˆ†æˆåŠŸã€ã•ã‚‰ãªã‚‹èª¿æ•´æ¤œè¨
- âŒ vs Greedy 0% â†’ å¤±æ•—ã€ä»£æ›¿ã‚¢ãƒ—ãƒ­ãƒ¼ãƒå¿…è¦

### Phase 2A: Iter 40æˆåŠŸã®å ´åˆ

**ã‚ªãƒ—ã‚·ãƒ§ãƒ³1**: Iter 40ã‚’ãã®ã¾ã¾ä½¿ç”¨  
**ã‚ªãƒ—ã‚·ãƒ§ãƒ³2**: Iter 35-45ã§è¤‡æ•°ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆè©•ä¾¡ã€æœ€è‰¯ã‚’é¸æŠ  
**ã‚ªãƒ—ã‚·ãƒ§ãƒ³3**: Iter 40ã‹ã‚‰ç¶™ç¶šãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆæ—©æœŸåœæ­¢æ©Ÿèƒ½è¿½åŠ ï¼‰

### Phase 2B: Iter 40å¤±æ•—ã®å ´åˆ

#### Option 1: æ–°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§Iter 40ã¾ã§è¨“ç·´

```bash
# æ–°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§Iter 40ã¾ã§ç¶™ç¶š
uv run python -c "
from blokus_ai.train import main
main(
    num_iterations=40,
    eval_interval=5,
    past_generations=[5, 10],
    value_loss_weight=0.1,  # ç¾åœ¨ã®è¨­å®š
    buffer_size=0,
    num_simulations=100,
)
"
```

**æœŸå¾…**: æ—§ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åŒæ§˜ã€Iter 30-40ã§çªç ´

#### Option 2: æ—©æœŸåœæ­¢æ©Ÿèƒ½è¿½åŠ 

```python
# train.pyã«è¿½åŠ 
early_stopping_patience = 3  # 3ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ”¹å–„ãªã—ã§åœæ­¢
best_correlation = -1
patience_counter = 0

for iteration in range(num_iterations):
    # ... training ...
    
    # Evaluationã§ç›¸é–¢ã‚’ãƒã‚§ãƒƒã‚¯
    if eval_correlation > best_correlation:
        best_correlation = eval_correlation
        patience_counter = 0
        save_checkpoint(f"checkpoint_best.pth")
    else:
        patience_counter += 1
        if patience_counter >= early_stopping_patience:
            print(f"Early stopping at iteration {iteration}")
            break
```

#### Option 3: Value loss weightã®èª¿æ•´

Iter 40ã¾ã§ã®æ—§ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯`value_loss_weight=1.0`ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰ã§æˆåŠŸã€‚

æ–°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®`value_loss_weight=0.1`ãŒä½ã™ãã‚‹å¯èƒ½æ€§:
- è©¦è¡Œ: 0.25, 0.5, 0.75, 1.0

#### Option 4: Imitation Learning (Greedy)

```python
# Greedyãƒãƒªã‚·ãƒ¼ã‚’æ•™å¸«ã¨ã—ã¦äº‹å‰è¨“ç·´
def pretrain_on_greedy(net, num_games=100):
    """Greedyæˆ¦ç•¥ã‚’imitation learningã§å­¦ç¿’"""
    for i in range(num_games):
        # Greedy policyã§ã‚²ãƒ¼ãƒ ç”Ÿæˆ
        samples = generate_greedy_game()
        
        # Policy lossã®ã¿ã§è¨“ç·´ï¼ˆGreedyæ‰‹ã‚’æ­£è§£ã¨ã™ã‚‹ï¼‰
        for sample in samples:
            greedy_move = get_greedy_move(sample.moves)
            policy_target = one_hot(greedy_move_index)
            
            logits, _ = net(...)
            loss = cross_entropy(logits, policy_target)
            loss.backward()
            optimizer.step()
    
    return net

# ãã®å¾Œself-playã§fine-tune
```

---

## ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®šã®æ¯”è¼ƒ

| è¨­å®š | æ—§ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ (Iter 40æˆåŠŸ) | æ–°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ (Iter 10æœªå®Œ) |
|------|-------------------------------|------------------------------|
| value_loss_weight | **1.0** | **0.1** âš ï¸ ä½ã™ã? |
| Replay buffer | **ç„¡åŠ¹** | **ç„¡åŠ¹** |
| MCTS simulations | **500** | **100** |
| Learning rate | 5e-4 | 1e-4 |
| Games per iter | 5 | 5 |

**ä»®èª¬**: æ–°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®`value_loss_weight=0.1`ãŒå­¦ç¿’ã‚’é…ã‚‰ã›ã¦ã„ã‚‹å¯èƒ½æ€§

---

## çµè«–

### ç¾çŠ¶

- âœ… **Value headã®å­¦ç¿’ã¯å¯èƒ½** (æ—§ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£Iter 40ã§ç›¸é–¢0.63é”æˆ)
- âŒ **å®Ÿæˆ¦æ€§èƒ½ã¯æœªç¢ºèª** (Greedyæˆ¦ç•¥ã«0%å‹ç‡å ±å‘Šã‚ã‚Š)
- âš ï¸ **éå­¦ç¿’ãƒªã‚¹ã‚¯** (Iter 50ã§å´©å£Š)
- âš ï¸ **æ–°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯æœªå®Œäº†** (Iter 10ã§åœæ­¢)

### æœ€å„ªå…ˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³

**Iter 40 (æ—§ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£) ã®å®Ÿæˆ¦è©•ä¾¡ã‚’ä»Šã™ãå®Ÿæ–½**

ã“ã‚Œã«ã‚ˆã‚Š:
1. Valueç›¸é–¢ã®æ”¹å–„ãŒå®Ÿæˆ¦æ€§èƒ½ã«ç¹‹ãŒã‚‹ã‹ç¢ºèª
2. æˆåŠŸãªã‚‰æœ€è‰¯ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨
3. å¤±æ•—ãªã‚‰æ ¹æœ¬çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒå¤‰æ›´ã‚’æ¤œè¨

### é•·æœŸçš„ãªæ”¹å–„

1. **æ—©æœŸåœæ­¢æ©Ÿèƒ½**: Iter 40-50ã®ã‚ˆã†ãªéå­¦ç¿’ã‚’é˜²ã
2. **Replay buffer**: Catastrophic forgettingã‚’é˜²ã
3. **Imitation Learning**: åŸºæœ¬æˆ¦ç•¥ã®äº‹å‰å­¦ç¿’
4. **Curriculum Learning**: å°ã•ã„ãƒœãƒ¼ãƒ‰ã‹ã‚‰é–‹å§‹

---

**æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ**: Phase 1 (Iter 40è©•ä¾¡)
